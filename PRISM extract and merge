library(devtools)
install_github("ropensci/prism")
library(prism)
library(sf)
library(dplyr)
library(tidyverse)
library(terra)
library(data.table)


##get daily PRISM data for maximum temperature from jan 1, 2013 to dec 31, 2023
#this saves into a folder on your computer labeled prismtmp

prism_set_dl_dir("~/prismtmp")

get_prism_dailys(
  type = "tmax", 
  minDate = "2013-01-01", 
  maxDate = "2023-12-31", 
  keepZip = FALSE
)

## extract the daily data and find the value for each centroid of ZCTAs, combined into one file

# making a centroids dataset (csv) into a shapefile
csv_sf <- st_as_sf(midwest_centroids, coords = c("INTPTLON10", "INTPTLAT10"))
str(csv_sf)

# setting datum/projection so both datasets are matching
st_crs(csv_sf) <- 4326

# remove duplicated ZCTAs if not done previously (crossing state boundaries)
csv_sf <- csv_sf %>%
  distinct(ZCTA5CE10,.keep_all = TRUE)

# Base directory containing your dated folders/files
# for example "/Users/lilyarp/prismtmp/prism_files" with all extracted prism files put into folder prism_files within prismtmp
base_dir <- "file_path_to_folder_containing_files"

# List of folder names (replace this with your folder name structure)
folder_names <- list.files(base_dir, full.names = TRUE)


# Initialize an empty list to store results
results_list <- list()

# Loop through each folder and process its corresponding raster file (may take a long time)
for (folder in folder_names) {
  # Construct the file path for the raster file
  raster_file <- file.path(folder, paste0(basename(folder), ".bil"))
  
  # Read the raster file
  data.r <- rast(raster_file)
  
  # Convert the raster to a data frame with coordinates
  data.d <- as.data.frame(data.r, xy = TRUE)
  
  # Convert the data frame into a spatial object
  data_sf <- st_as_sf(data.d, coords = c("x", "y"))
  
  # Set CRS for spatial compatibility
  st_crs(data_sf) <- 4326
  
  # Perform spatial join using st_nearest_feature
  join_sf <- csv_sf %>% 
    cbind(
      data_sf[st_nearest_feature(csv_sf, data_sf), ]
    )
  
  # Detect the date column dynamically by matching a typical date pattern
  # E.g., 8-digit format like "20230101" or similar
  date_column_name <- names(join_sf)[grep("\\d{8}", names(join_sf))]
  
  # Add a check to ensure the date column is found
  if (length(date_column_name) == 0) {
    stop("No column with a date pattern (e.g., YYYYMMDD) found in join_sf. Please verify column naming.")
  }
  
  # Rename the date column to include the folder identifier (to avoid conflicts)
  names(join_sf)[names(join_sf) == date_column_name] <- paste0("ExtractValue_", basename(folder))
  
  # Add to results list
  results_list[[basename(folder)]] <- join_sf
}


# for each item in results_list, extracts columns 3 and 12 (zip code and Tmax) and removes the geometry attributes
extracted_data <- lapply(results_list, function(df) {
  dt <- as.data.table(df[, c(3, 12)])
  dt$geometry <- NULL # Remove the "geometry" column if it exists as a list
  dt
})

# merges all extracted datasets within the extracted_data list, output is a column of zipcodes and x columns of Tmax daily values
final_dataset <- Reduce(function(x, y) {
  merge(x, y, by = "ZCTA5CE10", all.x = TRUE)
}, extracted_data)

# turn data from wide format to long
final_long <- melt(final_dataset, id = "ZCTA5CE10")

# change the value column to "Tmax" 
colnames(final_long)[3] <- "Tmax"

# extract the date from the file name now located in the variable column
final_long$date <- substr(final_long$variable, start = 38, stop = 45)

# turn the date into date format
final_long$date <- as.Date(final_long$date, "%Y%m%d")

# you now have a file of daily Tmax values for your zipcodes of interest
